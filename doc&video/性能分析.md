# GPU加速下的可视化向量场

## 点运动加速

第一个计算使用在点的运动。正常逻辑是通过定时调用CPU中的运动函数。遍历矩阵做一个做一个矩阵加法：
$$
RecPoint = PrePoint + Step \times Direction
$$

并进行边界检测，及时更新所在平面。

### CPU实现

第一种方法：直接使用 `libigl` 重构的运算符：

```c++
 moving_point = moving_point + moving_point_direct * B.moving_point_step;
```

第二种方法：使用$O(n)$遍历矩阵：
```c++
for (int i = 0; i < F.rows(); i++) {add}
```

### GPU实现

将CPU第二种方法，传到GPU中计算即可。

困难主要是体现在参数传递：把需要传递的`Eigen::MatrixXi`变量全部改为`double`类型，使用时做一个 mapping 即可。

### 正确性验证

通过比较CPU和GPU计算结果，更改数据集量级之后记过一致。

### 性能分析

这里只考虑数值计算时间，不考虑数据传入时间。

| 数据量 | CPU重构 | CPU遍历  | GPU遍历  |
| :----: | :-----: | :------: | :------: |
|  100   |    -    |  660μs   | 1404.6μs |
|  1000  |    -    | 674.4μs  | 1467.2μs |
|  5000  |    -    | 1201.2μs |  1255μs  |
|  6000  |    -    | 1388.4μs | 1559.6μs |
|  8000  |    -    | 1424.8μs | 1388.4μs |
| 10000  |    -    | 1291.8μs | 940.6μs  |
| 20000  |    -    | 3424.6μs |  1720μs  |
| 50000  |    -    | 8634.8μs | 2030.4μs |
| 100000 |    -    | 9654.8μs | 1022.4μs |

*由于数据的随机性可能在某些随机情况下表现不同*

观察得出大约在大于10000点数目之后GPU会有明显的提升效果。

考虑在实际情况下，需要考虑到实际传输数据所需要的时间：

| 数据量 | 数据传入+计算 | 计算时间  | 传递时间估计 |
| :----: | :-----------: | :-------: | :----------: |
| 11259  |   1649.85μs   | 1373.42μs |   276.43μs   |
|  7250  |   1297.14μs   |  965.8μs  |   331.34μs   |
|  5356  |   1101.1μs    | 620.28μs  |   480.82μs   |

能够粗略估计传递时间等于计算时间，所以当数据量基本在20000以上应该能够保证加速之后的效果稳定优于CPU上的运算。
